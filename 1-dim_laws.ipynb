{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ed6347",
   "metadata": {},
   "source": [
    "# 1 dimensional laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8389a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 14:38:53.374861: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-25 14:38:53.374885: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d401d",
   "metadata": {},
   "source": [
    "## Wolfram's 256 Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd0766",
   "metadata": {},
   "source": [
    "These are all cellular automaton rules for a 1-d array with only neares neighbour interaction. There are therefore only three cells (L,C,R) determining the outcome of one cell (C). This gives 2^3=8 possible combinations that can give rise to an outcome of 2 possibilities. Thus there are 2^8=256 possible rules. \n",
    "\n",
    "The following function generates each of these rules.\n",
    " \n",
    "Input:  \n",
    "num = number of rule  \n",
    "inp = string of input bits   \n",
    "t = number of timesteps calculated  \n",
    "\n",
    "Output: an array of arrays each for one timestep beginning with the input array. \n",
    "\n",
    "The boudary conditions are periodic\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88558917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CellularAutomata(num,inp,t):\n",
    "    bnum = np.flip(np.fromiter(np.binary_repr(num,width=8),dtype=int))\n",
    "    out = [np.fromiter(inp,dtype=int)]\n",
    "    lin = len(inp)\n",
    "    currinp = inp\n",
    "    for n in range(t):\n",
    "        outnow = []\n",
    "        for i in range(len(inp)):\n",
    "            outnow = np.append(outnow,bnum[int(str(currinp[(i-1)%lin])+str(currinp[(i)%lin])+str(currinp[(i+1)%lin]),2)])\n",
    "\n",
    "        currinp =''.join([str(int(elem)) for elem in outnow])\n",
    "        out = np.append(out,[outnow],axis=0)\n",
    "    return(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a7aed1",
   "metadata": {},
   "source": [
    "## Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd85489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10000 #batch size\n",
    "L=3 #Length of box\n",
    "rule= 170\n",
    "time = 1\n",
    "\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "\n",
    "for i in range(N):\n",
    "    #x=[0,0,0]\n",
    "    #x[np.random.randint(0,3)]=1\n",
    "    x=np.random.randint(0,2,L)\n",
    "    x_train.append(np.copy(x))\n",
    "    #y_train.append(np.copy(CellularAutomata(rule,''.join([str(int(elem)) for elem in x]),time)[time]))\n",
    "    y_train.append(np.copy(CellularAutomata(rule,''.join([str(int(elem)) for elem in x]),time)[time,1]))\n",
    "    #print(''.join([str(int(elem)) for elem in x]),CellularAutomata(rule,''.join([str(int(elem)) for elem in x]),time)[time,0])\n",
    "\n",
    "#for i in range(20):\n",
    " #   print(x_train[i],y_train[i])\n",
    "    \n",
    "x_train = np.array(x_train).reshape(N,L,1)\n",
    "y_train = np.array(y_train).reshape(N,1)\n",
    "#print(x_train.shape,y_train.shape)\n",
    "#print(x_train[0],y_train[0],CellularAutomata(rule,''.join([str(int(elem)) for elem in x_train[0]]),time)[time])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf11431",
   "metadata": {},
   "source": [
    "## Models\n",
    "useful resource for understanding what is going on:  \n",
    "Padding https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/  \n",
    "Guide to 2d conv layers https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/  \n",
    "Guide to 1d conv layers https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/  \n",
    "shapes, dimensions and units https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8968d",
   "metadata": {},
   "source": [
    "### Dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf2eb79",
   "metadata": {},
   "source": [
    "### 1-D Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8e6558cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Simple convolution without stride ######\n",
    "class SimpleConv(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleConv, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], 1),\n",
    "                               initializer='random_normal',\n",
    "                               trainable=True)\n",
    "    def call(self, inputs):\n",
    "        print(self.w)\n",
    "        return tf.matmul(inputs, self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41147436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add periodic padding\n",
    "def periodic_padding(imbatch, padding=1):\n",
    "    '''\n",
    "    Create a periodic padding (wrap) around an image batch, to emulate \n",
    "    periodic boundary conditions. Padding occurs along the middle two axes\n",
    "    '''\n",
    "    pad_u = imbatch[:, -padding:, :]\n",
    "    pad_b = imbatch[:, :padding, :]\n",
    "\n",
    "    partial_image = tf.concat([pad_u, imbatch, pad_b], axis=1)\n",
    "\n",
    "#    pad_l = partial_image[..., -padding:, :]\n",
    " #   pad_r = partial_image[..., :padding, :]\n",
    "\n",
    " #   padded_imbatch = tf.concat([pad_l, partial_image, pad_r], axis=2)\n",
    "          \n",
    "    \n",
    "    return padded_imbatch\n",
    "\n",
    "class Wraparound2D(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Apply periodic boundary conditions on an image by padding \n",
    "    along the axes\n",
    "    padding : int or tuple, the amount to wrap around    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, padding=2, **kwargs):\n",
    "        super(Wraparound2D, self).__init__()\n",
    "        self.padding = padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "be67d0ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'simple_conv_54/Variable:0' shape=(1, 1) dtype=float32>\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "wraparound2d_2 (Wraparound2D (None, 3, 1)              0         \n",
      "_________________________________________________________________\n",
      "simple_conv_54 (SimpleConv)  (None, 3, 1)              1         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## (Approx) Model from Paper https://arxiv.org/pdf/1809.02942.pdf\n",
    "nhood = 1\n",
    "shape = (1,L)\n",
    "wspan,hspan = shape\n",
    "diameter = 3\n",
    "layer_dims=[2^L,20]\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer((hspan,1))) \n",
    "model.add(Wraparound2D(padding=nhood)) #adding periodic padding extending by nhood\n",
    "model.add(SimpleConv())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(L,activation=\"softmax\"))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdf7ed",
   "metadata": {},
   "source": [
    "## Execute learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f851c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'simple_conv_54/Variable:0' shape=(1, 1) dtype=float32, numpy=array([[-0.02625071]], dtype=float32)>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes (10000, 1) and (10000, 3) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31677/3471988519.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    143\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mag_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   1663\u001b[0m                                  lambda: y_true)\n\u001b[1;32m   1664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1665\u001b[0;31m   return backend.categorical_crossentropy(\n\u001b[0m\u001b[1;32m   1666\u001b[0m       y_true, y_pred, from_logits=from_logits, axis=axis)\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4837\u001b[0m   \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4838\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4839\u001b[0;31m   \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4841\u001b[0m   \u001b[0;31m# Use logits whenever they are available. `softmax` and `sigmoid`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \"\"\"\n\u001b[1;32m   1160\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (10000, 1) and (10000, 3) are incompatible"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "#loss_fn = tf.keras.metrics.BinaryAccuracy()\n",
    "#loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "#loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"auto\",name=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "\n",
    "predictions = model(x_train).numpy()\n",
    "\n",
    "loss_fn(y_train, predictions).numpy()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "              loss=loss_fn,\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    "                #metrics= [tf.keras.losses.CategoricalCrossentropy()]\n",
    "             )\n",
    "train_history = model.fit(x=x_train, y=y_train, epochs=200,verbose=0)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(train_history.history['loss'], 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba25372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
