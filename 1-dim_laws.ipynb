{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ed6347",
   "metadata": {},
   "source": [
    "# 1 dimensional laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8389a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import tensorflow as tf\n",
    "from sympy import poly\n",
    "from sympy.abc import x,y,z, k\n",
    "from sympy import degree\n",
    "from sympy import *\n",
    "import sympy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e8933",
   "metadata": {},
   "source": [
    "# CSV Write or read works like this\n",
    "\n",
    "see https://www.pythontutorial.net/python-basics/python-write-csv-file/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc2c3614",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/csv_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24264/2899427177.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m###Write###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# open the file in the write mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path/to/csv_file'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# create the csv writer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/csv_file'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "###Write###\n",
    "# open the file in the write mode\n",
    "f = open('path/to/csv_file', 'w')\n",
    "\n",
    "# create the csv writer\n",
    "writer = csv.writer(f)\n",
    "\n",
    "# write a row to the csv file\n",
    "writer.writerow(row)\n",
    "\n",
    "# close the file\n",
    "f.close()\n",
    "\n",
    "###Read###\n",
    "\n",
    "# open the file in the write mode\n",
    "with open('path/to/csv_file', 'w') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d401d",
   "metadata": {},
   "source": [
    "## Wolfram's 256 Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd0766",
   "metadata": {},
   "source": [
    "These are all cellular automaton rules for a 1-d array with only neares neighbour interaction. There are therefore only three cells (L,C,R) determining the outcome of one cell (C). This gives 2^3=8 possible combinations that can give rise to an outcome of 2 possibilities. Thus there are 2^8=256 possible rules. \n",
    "\n",
    "The following function generates each of these rules.\n",
    " \n",
    "Input:  \n",
    "num = number of rule  \n",
    "inp = string of input bits   \n",
    "t = number of timesteps calculated  \n",
    "\n",
    "Output: an array of arrays each for one timestep beginning with the input array. \n",
    "\n",
    "The boudary conditions are periodic\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88558917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CellularAutomata(num,inp,t):\n",
    "    bnum = np.flip(np.fromiter(np.binary_repr(num,width=8),dtype=int))\n",
    "    out = [np.fromiter(inp,dtype=int)]\n",
    "    lin = len(inp)\n",
    "    currinp = inp\n",
    "    for n in range(t):\n",
    "        outnow = []\n",
    "        for i in range(len(inp)):\n",
    "            outnow = np.append(outnow,bnum[int(str(currinp[(i-1)%lin])+str(currinp[(i)%lin])+str(currinp[(i+1)%lin]),2)])\n",
    "\n",
    "        currinp =''.join([str(int(elem)) for elem in outnow])\n",
    "        out = np.append(out,[outnow],axis=0)\n",
    "    return(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c679bb9",
   "metadata": {},
   "source": [
    "## Pol deg of rule\n",
    "\n",
    "Resources on sympy for polynomials: https://docs.sympy.org/latest/modules/polys/reference.html  \n",
    "\n",
    "Input: Rule number (integer)  \n",
    "Output: Polynomial degree of rule (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5191e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one(a,x):\n",
    "    u=1\n",
    "    for i in range(len(x)):\n",
    "        u=u*(1+(2*a[i]-1)*(2*x[i]-1))/2\n",
    "    return(u.expand())\n",
    "\n",
    "def ACAP(num):\n",
    "    u=0\n",
    "    x=[sympy.Symbol('x1'),sympy.Symbol('x2'),sympy.Symbol('x3')]\n",
    "    for i in [0,1]:\n",
    "        for j in [0,1]:\n",
    "            for l in [0,1]:\n",
    "                u=u+CellularAutomata(num,[i,j,l],1)[1,1]*one([i,j,l],x)\n",
    "    return(u)\n",
    "    \n",
    "                \n",
    "def PolyDegOfRule(num):\n",
    "    return(sympy.Poly(ACAP(num)).total_degree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a7aed1",
   "metadata": {},
   "source": [
    "## Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd85489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N=10000 #batch size\n",
    "#L=3 #Length of box\n",
    "#rule= 22 #170 is movement to the left x_i' = x_{i+1}\n",
    "#time = 1\n",
    "\n",
    "def data_generation(N,L,rule,time):\n",
    "    x_train=[]\n",
    "    y_train=[]\n",
    "\n",
    "\n",
    "    for i in range(N):\n",
    "        #x=[0,0,0]\n",
    "        #x[np.random.randint(0,3)]=1\n",
    "        x=np.random.randint(0,2,L).astype(float)\n",
    "        x_train.append(np.copy(x))\n",
    "        #y_train.append(np.copy(CellularAutomata(rule,''.join([str(int(elem)) for elem in x]),time)[time]))\n",
    "        y_train.append(np.copy(CellularAutomata(rule,''.join([str(int(elem)) for elem in x]),time)[time,1]))\n",
    "        #print(''.join([str(int(elem)) for elem in x]),CellularAutomata(rule,''.join([str(int(elem)) for elem in x]),time)[time,0])\n",
    "\n",
    "    #for i in range(20):\n",
    "     #   print(x_train[i],y_train[i])\n",
    "\n",
    "    x_train = np.array(x_train).reshape(N,L,1)\n",
    "    y_train = np.array(y_train).reshape(N,1)\n",
    "    return((x_train,y_train))\n",
    "    #print(x_train.shape,y_train.shape)\n",
    "    #print(x_train[0],y_train[0],CellularAutomata(rule,''.join([str(int(elem)) for elem in x_train[0]]),time)[time])\n",
    "\n",
    "(x_train,y_train)=data_generation(10000,3,22,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf11431",
   "metadata": {},
   "source": [
    "## Models\n",
    "useful resource for understanding what is going on:  \n",
    "Padding https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/  \n",
    "Guide to 2d conv layers https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/  \n",
    "Guide to 1d conv layers https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/  \n",
    "shapes, dimensions and units https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8968d",
   "metadata": {},
   "source": [
    "### Dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf2eb79",
   "metadata": {},
   "source": [
    "### 1-D Convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5f740",
   "metadata": {},
   "source": [
    "Tutorial custom layers: https://www.tensorflow.org/tutorials/customization/custom_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d246323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [1.]]]\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "tf.Tensor(\n",
      "[[-1.1744114]\n",
      " [-1.3443956]\n",
      " [-1.3443956]], shape=(3, 1), dtype=float32)\n",
      "[array([[0., 0., 1.]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:18:45.929422: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-06 16:18:45.929444: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-06 16:18:45.929464: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (manu-ThinkPad-T460s): /proc/driver/nvidia/version does not exist\n",
      "2022-05-06 16:18:45.929694: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "class SimpleConv(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_neighbours):\n",
    "        super(SimpleConv, self).__init__()\n",
    "        self.num_neighbours = num_neighbours\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[int(input_shape[-1]),\n",
    "                                             self.num_neighbours])\n",
    "#        self.kernel = self.add_weight(\"kernel\",tf.constant([[0],[0],[1]]))\n",
    "    #        self.bias = self.add_weight(\"bias\",\n",
    "#                                      shape=[int(input_shape[-1]),\n",
    " #                                            self.num_neighbours])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inshape = tf.shape(inputs)\n",
    "#        return tf.matmul(inputs, self.kernel)\n",
    "        return tf.reshape(tf.tensordot(inputs,self.kernel,axes=2),(inshape[0],1))\n",
    "#        return tf.reshape(tf.tensordot(inputs,tf.constant([[0.,0,1]]),axes=2),(inshape[0],1))\n",
    "\n",
    "layer = SimpleConv(3)\n",
    "print(x_train[0:3])\n",
    "print(y_train[0:3])\n",
    "#layer.set_weights(np.array([1]))\n",
    "print(layer(x_train[0:3]))\n",
    "layer.set_weights([np.array([[0,0,1]])])\n",
    "print(layer.get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae8af720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]\n",
      "  [0.]]]\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]], shape=(5, 1), dtype=float32)\n",
      "[array([[0., 0., 1.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#layer = SimpleConv()\n",
    "inp = x_train[0:5]\n",
    "\n",
    "print(inp)\n",
    "print( y_train[0:5])\n",
    "#print(inp.shape)\n",
    "#layer(inp)\n",
    "#layer = tf.keras.layers.Conv1D(\n",
    "#1,3, activation='relu', input_shape=((3,1)))\n",
    "print(layer(inp))\n",
    "print(layer.get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be67d0ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer((3,1))) \n",
    "    #model.add(tf.keras.layers.Flatten())\n",
    "    #model.add(tf.keras.layers.Dense(3,activation=\"relu\"))\n",
    "    #model.add(tf.keras.layers.Reshape((3,1)))\n",
    "    model.add(SimpleConv(3))\n",
    "    model.add(tf.keras.layers.Reshape((1,1)))\n",
    "    model.add(SimpleConv(1))\n",
    "    model.add(tf.keras.layers.Reshape((1,1)))\n",
    "    model.add(SimpleConv(1))\n",
    "    model.add(tf.keras.layers.Reshape((1,1)))\n",
    "    model.add(SimpleConv(1))\n",
    "    model.add(tf.keras.layers.Reshape((1,1)))\n",
    "    model.add(SimpleConv(1))\n",
    "    model.add(tf.keras.layers.Reshape((1,1)))\n",
    "    model.add(SimpleConv(1))\n",
    "    model.add(tf.keras.layers.Reshape((1,1)))\n",
    "    model.add(SimpleConv(1))\n",
    "    model.add(tf.keras.layers.Reshape((1,1)))\n",
    "    model.add(SimpleConv(1))\n",
    "    model.add(tf.keras.layers.Reshape((1,1)))\n",
    "    model.add(SimpleConv(1))\n",
    "    model.add(tf.keras.layers.Reshape((1,1)))\n",
    "    model.add(SimpleConv(1))\n",
    "    model.add(tf.keras.layers.Reshape((1,1)))\n",
    "    model.add(SimpleConv(1))\n",
    "    model.add(tf.keras.layers.Reshape((1,1)))\n",
    "    model.add(SimpleConv(1))\n",
    "    #model.add(tf.keras.layers.Conv1D(1,3, activation='softmax', input_shape=((3,1))))\n",
    "    #model.add(tf.keras.layers.Conv1D(100,3, activation='relu', input_shape=((1,100))))\n",
    "\n",
    "    #model.add(tf.keras.layers.Softmax())\n",
    "    #tf.keras.layers.Activation('sigmoid')\n",
    "\n",
    "    #model.add(tf.keras.activations.sigmoid())\n",
    "    #model.add(tf.keras.layers.Dense(3,activation=\"relu\"))\n",
    "    #model.add(tf.keras.layers.Dense(1,activation=\"softmax\"))\n",
    "    #model.layers[0].set_weights([np.array([[1,1,1]])])#Initializing with almost the right law converges, but never with sometheing a bit more off\n",
    "    #model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdf7ed",
   "metadata": {},
   "source": [
    "## Execute learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f851c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:19:29.570461: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.1147 - accuracy: 0.8870\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 9.3183e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.3599e-06 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1155e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def learn(inp_model,x_train,y_train,epochs,verbose):\n",
    "    #loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True) #Logits true means output values are any real numbers\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    #loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    predictions = inp_model(x_train).numpy()\n",
    "    #print(loss_fn(y_train, predictions).numpy())\n",
    "\n",
    "    inp_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "                  loss=loss_fn,\n",
    "                  #metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    "                  metrics=['accuracy']\n",
    "                    #metrics= [tf.keras.losses.CategoricalCrossentropy()]\n",
    "                 )\n",
    "    train_history = model.fit(x=x_train, y=y_train, epochs=epochs,verbose=verbose)\n",
    "  #  plt.title(\"Loss\")\n",
    "   # plt.plot(train_history.history['loss'], 'k')\n",
    "    return(model,train_history)\n",
    "model=define_model()\n",
    "(x_train,y_train) = data_generation(1000,3,170,1)\n",
    "learn(model,x_train,y_train,5,1)[1].history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f34c2ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "GeneratorsNeeded",
     "evalue": "Cannot initialize from 'dict' without generators",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGeneratorsNeeded\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24264/4247878632.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpoldeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolyDegOfRule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoldeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# write a row to the csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24264/840463308.py\u001b[0m in \u001b[0;36mPolyDegOfRule\u001b[0;34m(num)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mPolyDegOfRule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mACAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_degree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sympy/polys/polytools.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, rep, *gens, **args)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;31m# Poly does not pass its args to Basic.__new__ to be stored in _args so we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sympy/polys/polytools.py\u001b[0m in \u001b[0;36m_from_expr\u001b[0;34m(cls, rep, opt)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;34m\"\"\"Construct a polynomial from an expression. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dict_from_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sympy/polys/polytools.py\u001b[0m in \u001b[0;36m_from_dict\u001b[0;34m(cls, rep, opt)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             raise GeneratorsNeeded(\n\u001b[0m\u001b[1;32m    249\u001b[0m                 \"Cannot initialize from 'dict' without generators\")\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mGeneratorsNeeded\u001b[0m: Cannot initialize from 'dict' without generators"
     ]
    }
   ],
   "source": [
    "acc_deg=[]\n",
    "path='data.csv'\n",
    "#f = open(path, 'w') # open the file in the write mode\n",
    "# create the csv writer\n",
    "\n",
    "for i in range(1,256):\n",
    "    \n",
    "    model=define_model()\n",
    "    (x_train,y_train) = data_generation(1000,3,i,1)\n",
    "    learn(model,x_train,y_train,10,0)\n",
    "    learn(model,x_train,y_train,10,0)\n",
    "    accuracy = learn(model,x_train,y_train,10,0)[1].history['accuracy'][-1]\n",
    "    poldeg = PolyDegOfRule(i)\n",
    "    row = (accuracy, poldeg)   \n",
    "    # write a row to the csv file\n",
    "    with open(path,'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)\n",
    "    #acc_deg.append((accuracy,poldeg))\n",
    "    \n",
    "# close the file\n",
    "#f.close()\n",
    "#acc_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e25ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(170,180):\n",
    "    print(PolyDegOfRule(i),\": \",ACAP(i),\"== \",ACAP(i).subs('x1','x').subs('x2','x').subs('x3','x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba25372",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24264/2976540957.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#print(x_train[0:3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(model(x_train)[20:40].numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(sum(np.around(tf.keras.activations.sigmoid(model.get_weights()[0]))[:],[\"x1\",\"+ x2\",\"+ x3\"][:]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "#print(x_train[0:3])\n",
    "print(y_train[20:40])\n",
    "#print(model(x_train)[20:40].numpy())\n",
    "np.around(tf.keras.activations.sigmoid(model(x_train)[20:40]))\n",
    "#print(sum(np.around(tf.keras.activations.sigmoid(model.get_weights()[0]))[:],[\"x1\",\"+ x2\",\"+ x3\"][:]))\n",
    "weights=np.around(tf.keras.activations.sigmoid(model.get_weights()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c7ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
