{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ed6347",
   "metadata": {},
   "source": [
    "# 1 dimensional laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8389a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 15:07:44.249860: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-04 15:07:44.249920: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d401d",
   "metadata": {},
   "source": [
    "## Wolfram's 256 Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd0766",
   "metadata": {},
   "source": [
    "These are all cellular automaton rules for a 1-d array with only neares neighbour interaction. There are therefore only three cells (L,C,R) determining the outcome of one cell (C). This gives 2^3=8 possible combinations that can give rise to an outcome of 2 possibilities. Thus there are 2^8=256 possible rules. \n",
    "\n",
    "The following function generates each of these rules.\n",
    " \n",
    "Input:  \n",
    "num = number of rule  \n",
    "inp = string of input bits   \n",
    "t = number of timesteps calculated  \n",
    "\n",
    "Output: an array of arrays each for one timestep beginning with the input array. \n",
    "\n",
    "The boudary conditions are periodic\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88558917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CellularAutomata(num,inp,t):\n",
    "    bnum = np.flip(np.fromiter(np.binary_repr(num,width=8),dtype=int))\n",
    "    out = [np.fromiter(inp,dtype=int)]\n",
    "    lin = len(inp)\n",
    "    currinp = inp\n",
    "    for n in range(t):\n",
    "        outnow = []\n",
    "        for i in range(len(inp)):\n",
    "            outnow = np.append(outnow,bnum[int(str(currinp[(i-1)%lin])+str(currinp[(i)%lin])+str(currinp[(i+1)%lin]),2)])\n",
    "\n",
    "        currinp =''.join([str(int(elem)) for elem in outnow])\n",
    "        out = np.append(out,[outnow],axis=0)\n",
    "    return(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a7aed1",
   "metadata": {},
   "source": [
    "## Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "dd85489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000 #batch size\n",
    "L=3 #Length of box\n",
    "rule= 170\n",
    "time = 1\n",
    "\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "\n",
    "for i in range(N):\n",
    "    #x=[0,0,0]\n",
    "    #x[np.random.randint(0,3)]=1\n",
    "    x=np.random.randint(0,2,L).astype(float)\n",
    "    x_train.append(np.copy(x))\n",
    "    #y_train.append(np.copy(CellularAutomata(rule,''.join([str(int(elem)) for elem in x]),time)[time]))\n",
    "    y_train.append(np.copy(CellularAutomata(rule,''.join([str(int(elem)) for elem in x]),time)[time,1]))\n",
    "    #print(''.join([str(int(elem)) for elem in x]),CellularAutomata(rule,''.join([str(int(elem)) for elem in x]),time)[time,0])\n",
    "\n",
    "#for i in range(20):\n",
    " #   print(x_train[i],y_train[i])\n",
    "    \n",
    "x_train = np.array(x_train).reshape(N,L,1)\n",
    "y_train = np.array(y_train).reshape(N,1)\n",
    "#print(x_train.shape,y_train.shape)\n",
    "#print(x_train[0],y_train[0],CellularAutomata(rule,''.join([str(int(elem)) for elem in x_train[0]]),time)[time])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf11431",
   "metadata": {},
   "source": [
    "## Models\n",
    "useful resource for understanding what is going on:  \n",
    "Padding https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/  \n",
    "Guide to 2d conv layers https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/  \n",
    "Guide to 1d conv layers https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/  \n",
    "shapes, dimensions and units https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8968d",
   "metadata": {},
   "source": [
    "### Dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf2eb79",
   "metadata": {},
   "source": [
    "### 1-D Convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5f740",
   "metadata": {},
   "source": [
    "Tutorial customb layers: https://www.tensorflow.org/tutorials/customization/custom_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "a022ccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [1.]]]\n",
      "tf.Tensor([-1.1612104  -0.09187949], shape=(2,), dtype=float32)\n",
      "[array([[-1.0905125, -1.0693309,  0.998633 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "class SimpleConv(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_neighbours):\n",
    "        super(SimpleConv, self).__init__()\n",
    "        self.num_neighbours = num_neighbours\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[int(input_shape[-1]),\n",
    "                                             self.num_neighbours])\n",
    "\n",
    "    def call(self, inputs):\n",
    "#        return tf.matmul(inputs, self.kernel)\n",
    "        return tf.tensordot(inputs,self.kernel,axes=2)\n",
    "layer = SimpleConv(3)\n",
    "print(x_train[0:2])\n",
    "print(layer(x_train[0:2]))\n",
    "print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "0e8690e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [1.]]]\n",
      "3\n",
      "tf.Tensor(\n",
      "[[[0.        ]]\n",
      "\n",
      " [[0.        ]]\n",
      "\n",
      " [[0.07612252]]], shape=(3, 1, 1), dtype=float32)\n",
      "[array([[[-0.9108751 ]],\n",
      "\n",
      "       [[ 0.04261279]],\n",
      "\n",
      "       [[ 0.07612252]]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#layer = SimpleConv()\n",
    "inp = x_train[0:3]\n",
    "print(inp)\n",
    "#print(inp.shape)\n",
    "#layer(inp)\n",
    "#layer = tf.keras.layers.Conv1D(\n",
    "#1,3, activation='relu', input_shape=((3,1)))\n",
    "print(layer(inp))\n",
    "print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "be67d0ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_14 (Conv1D)           (None, 1, 1)              4         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer((3,1))) \n",
    "#model.add(SimpleConv())\n",
    "model.add(tf.keras.layers.Conv1D(1,3, activation='relu', input_shape=((3,1))))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdf7ed",
   "metadata": {},
   "source": [
    "## Execute learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "f851c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.5130\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 6.0875e-05 - accuracy: 0.5130\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 4.5015e-05 - accuracy: 0.5130\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 4.2961e-05 - accuracy: 0.5130\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 4.1224e-05 - accuracy: 0.5130\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.9418e-05 - accuracy: 0.5130\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.7601e-05 - accuracy: 0.5130\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.5811e-05 - accuracy: 0.5130\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.4076e-05 - accuracy: 0.5130\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 3.2375e-05 - accuracy: 0.5130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f18e8014370>]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "#loss_fn = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "#loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"auto\",name=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "\n",
    "predictions = model(x_train).numpy()\n",
    "\n",
    "loss_fn(y_train, predictions).numpy()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1),\n",
    "              loss=loss_fn,\n",
    "              #metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    "              metrics=['accuracy']\n",
    "                #metrics= [tf.keras.losses.CategoricalCrossentropy()]\n",
    "             )\n",
    "train_history = model.fit(x=x_train, y=y_train, epochs=10,verbose=1)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(train_history.history['loss'], 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "2ba25372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train[3])\n",
    "print(CellularAutomata(170,[1,0,0],1))\n",
    "model(x_train)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "512bca79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CellularAutomata(170,[1,0,0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb0658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
