{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ed6347",
   "metadata": {},
   "source": [
    "# 1 dimensional laws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8389a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 17:09:57.316820: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-09 17:09:57.316850: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d401d",
   "metadata": {},
   "source": [
    "## Wolfram's 256 Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd0766",
   "metadata": {},
   "source": [
    "These are all cellular automaton rules for a 1-d array with only neares neighbour interaction. There are therefore only three cells (L,C,R) determining the outcome of one cell (C). This gives 2^3=8 possible combinations that can give rise to an outcome of 2 possibilities. Thus there are 2^8=256 possible rules. \n",
    "\n",
    "The following function generates each of these rules.\n",
    " \n",
    "Input:  \n",
    "num = number of rule  \n",
    "inp = string of input bits   \n",
    "t = number of timesteps calculated  \n",
    "\n",
    "Output: an array of arrays each for one timestep beginning with the input array. \n",
    "\n",
    "The boudary conditions are periodic\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88558917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CellularAutomata(num,inp,t):\n",
    "    bnum = np.flip(np.fromiter(np.binary_repr(num,width=8),dtype=int))\n",
    "    out = [np.fromiter(inp,dtype=int)]\n",
    "    lin = len(inp)\n",
    "    currinp = inp\n",
    "    for n in range(t):\n",
    "        outnow = []\n",
    "        for i in range(len(inp)):\n",
    "            outnow = np.append(outnow,bnum[int(str(currinp[(i-1)%lin])+str(currinp[(i)%lin])+str(currinp[(i+1)%lin]),2)])\n",
    "\n",
    "        currinp =''.join([str(int(elem)) for elem in outnow])\n",
    "        out = np.append(out,[outnow],axis=0)\n",
    "    return(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a7aed1",
   "metadata": {},
   "source": [
    "## Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dd85489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=100 #batch size\n",
    "L=3 #Length of box\n",
    "rule= 170\n",
    "time = 1\n",
    "\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "\n",
    "for i in range(N):\n",
    "    #x=[0,0,0]\n",
    "    #x[np.random.randint(0,3)]=1\n",
    "    x=np.random.randint(0,2,L)\n",
    "    x_train.append(np.copy(x))\n",
    "    #y_train.append(np.copy(CellularAutomata(rule,''.join([str(int(elem)) for elem in x]),time)[time]))\n",
    "    y_train.append(np.copy(CellularAutomata(rule,''.join([str(int(elem)) for elem in x]),time)[time,1]))\n",
    "    #print(''.join([str(int(elem)) for elem in x]),CellularAutomata(rule,''.join([str(int(elem)) for elem in x]),time)[time,0])\n",
    "\n",
    "#for i in range(20):\n",
    " #   print(x_train[i],y_train[i])\n",
    "    \n",
    "x_train = np.array(x_train).reshape(N,L,1)\n",
    "y_train = np.array(y_train).reshape(N,1)\n",
    "#print(x_train.shape,y_train.shape)\n",
    "#print(x_train[0],y_train[0],CellularAutomata(rule,''.join([str(int(elem)) for elem in x_train[0]]),time)[time])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf11431",
   "metadata": {},
   "source": [
    "## Models\n",
    "useful resource for understanding what is going on:  \n",
    "Padding https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/  \n",
    "Guide to 2d conv layers https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/  \n",
    "Guide to 1d conv layers https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/  \n",
    "shapes, dimensions and units https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8968d",
   "metadata": {},
   "source": [
    "### Dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf2eb79",
   "metadata": {},
   "source": [
    "### 1-D Convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5f740",
   "metadata": {},
   "source": [
    "Tutorial customb layers: https://www.tensorflow.org/tutorials/customization/custom_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8e6558cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Simple convolution without stride ######\n",
    "class SimpleConv(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleConv, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.shape = input_shape\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], 1),\n",
    "                               initializer='random_normal',\n",
    "                               trainable=True)\n",
    "        print(input_shape[-1])\n",
    "    def call(self, inputs):\n",
    "        print(self.w)\n",
    "        return tf.add(np.array(tf.math.multiply(inputs, tf.transpose(self.w))).reshape(self.shape[0],self.shape[1],1),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "139d3b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "<tf.Variable 'simple_conv_93/Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[ 0.03635658],\n",
      "       [ 0.03677227],\n",
      "       [-0.04227185]], dtype=float32)>\n",
      "<tf.Variable 'simple_conv_93/Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[ 0.03635658],\n",
      "       [ 0.03677227],\n",
      "       [-0.04227185]], dtype=float32)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 1), dtype=float32, numpy=\n",
       "array([[[ 0.01720952],\n",
       "        [ 0.01740629],\n",
       "        [-0.02000954]],\n",
       "\n",
       "       [[ 0.01720952],\n",
       "        [ 0.03481259],\n",
       "        [-0.06002861]],\n",
       "\n",
       "       [[ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = SimpleConv()\n",
    "dense = tf.keras.layers.Dense(1)\n",
    "layer(np.array([[1.,1,1],[1,2,3],[0,0,0],[0,0,0]]))\n",
    "dense(layer(np.array([[1.,1,1],[1,2,3],[0,0,0],[0,0,0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "be67d0ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "<tf.Variable 'simple_conv_87/Variable:0' shape=(3, 1) dtype=float32>\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Exception encountered when calling layer \"simple_conv_87\" (type SimpleConv).\n\nin user code:\n\n    File \"/tmp/ipykernel_21509/59490006.py\", line 15, in call  *\n        return tf.add(np.array(tf.math.multiply(inputs, tf.transpose(self.w))).reshape(self.shape[0],self.shape[1],1),0)\n\n    NotImplementedError: Cannot convert a symbolic Tensor (simple_conv_87/Mul:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 100, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [132]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInputLayer((N,\u001b[38;5;241m3\u001b[39m))) \n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSimpleConv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(SimpleConv())\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(SimpleConv())\n",
      "File \u001b[0;32m~/Git/GitHub/golDeeplearning/jupyterenv/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Git/GitHub/golDeeplearning/jupyterenv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Git/GitHub/golDeeplearning/jupyterenv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Exception encountered when calling layer \"simple_conv_87\" (type SimpleConv).\n\nin user code:\n\n    File \"/tmp/ipykernel_21509/59490006.py\", line 15, in call  *\n        return tf.add(np.array(tf.math.multiply(inputs, tf.transpose(self.w))).reshape(self.shape[0],self.shape[1],1),0)\n\n    NotImplementedError: Cannot convert a symbolic Tensor (simple_conv_87/Mul:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 100, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer((N,3))) \n",
    "model.add(SimpleConv())\n",
    "model.add(SimpleConv())\n",
    "model.add(SimpleConv())\n",
    "model.add(SimpleConv())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(3,activation=\"softmax\"))\n",
    "model.add(tf.keras.layers.Dense(1,activation=\"softmax\"))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdf7ed",
   "metadata": {},
   "source": [
    "## Execute learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f851c8a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"sequential_13\" is incompatible with the layer: expected shape=(None, 100, 3), found shape=(100, 3, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [104]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"auto\",name=\"sparse_categorical_crossentropy\")\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      9\u001b[0m loss_fn(y_train, predictions)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     12\u001b[0m               loss\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m     13\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mBinaryAccuracy()]\n\u001b[1;32m     14\u001b[0m                 \u001b[38;5;66;03m#metrics= [tf.keras.losses.CategoricalCrossentropy()]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m              )\n",
      "File \u001b[0;32m~/Git/GitHub/golDeeplearning/jupyterenv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Git/GitHub/golDeeplearning/jupyterenv/lib/python3.8/site-packages/keras/engine/input_spec.py:264\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    265\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    266\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    267\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"sequential_13\" is incompatible with the layer: expected shape=(None, 100, 3), found shape=(100, 3, 1)"
     ]
    }
   ],
   "source": [
    "#loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "#loss_fn = tf.keras.metrics.BinaryAccuracy()\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "#loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"auto\",name=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "\n",
    "predictions = model(x_train).numpy()\n",
    "\n",
    "loss_fn(y_train, predictions).numpy()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1),\n",
    "              loss=loss_fn,\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    "                #metrics= [tf.keras.losses.CategoricalCrossentropy()]\n",
    "             )\n",
    "train_history = model.fit(x=x_train, y=y_train, epochs=5,verbose=1)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(train_history.history['loss'], 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba25372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
